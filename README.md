# Content Extractor with Vision LLM

GitHub Repository: [https://github.com/MDGrey33/content-extractor-with-vision](https://github.com/MDGrey33/content-extractor-with-vision)

This repository contains a Python project that extracts text and images from various file types (PDF, DOCX, PPTX), describes the images using Vision Language Models, and saves the results in a specified output directory.

## Features

- Extract text and images from PDF, DOCX, and PPTX files
- Describe images using local or cloud-based Vision Language Models
- Save extracted text and image descriptions in a specified output directory
- Detailed logging with timestamps for all operations
- User-friendly command-line interface for specifying input and output folders
- Modular and extensible code structure following SOLID principles
- Compare image descriptions generated by different models

## Installation

1. **Clone the Repository**

   ```bash
   [git clone https://github.com/MDGrey33/content-extractor-with-vision](https://github.com/MDGrey33/content-extractor-with-vision.git)
   cd file-extractor
   ```

2. **Install Poetry**

   If you haven't installed Poetry yet, you can do so by following the instructions on the [Poetry website](https://python-poetry.org/docs/#installation).

3. **Install Dependencies**

   System dependencies:
   - LibreOffice (required for DOCX/PPTX processing)
   - poppler (required for PDF processing)

   Installation commands:
   - macOS (using Homebrew):
     ```bash
     brew install --cask libreoffice
     brew install poppler
     ```

   - Ubuntu/Debian:
     ```bash
     sudo apt-get update
     sudo apt-get install libreoffice poppler-utils
     ```

   - Windows:
     - Download and install [LibreOffice](https://www.libreoffice.org/download/download/)
     - Download and install [poppler](http://blog.alivate.com.au/poppler-windows/)
     - Add the poppler `bin` directory to your system PATH

   Python dependencies:
   ```bash
   poetry install
   ```

## Setup Ollama

1. **Run Ollama Server**
   ```bash
   ollama serve
   ```

2. **Pull Required Model**
   ```bash
   ollama pull llama3.2-vision
   ```

## Configuration

The script's behavior can be customized through the `config.py` file:

```python
# Image description settings
DEFAULT_DESCRIBER = "ollama"  # or "openai"
DEFAULT_MODEL = "llama3.2-vision"  # or "gpt-4", "llava", etc.

# Extraction method settings
DEFAULT_PDF_EXTRACTOR = "page_as_image"  # or "text_and_images"
DEFAULT_DOCX_EXTRACTOR = "page_as_image"  # or "text_and_images"
```

### Environment Variables
Before using OpenAI's vision models, set your OpenAI API key as an environment variable:

```bash
# For Unix/Linux/macOS
export OPENAI_API_KEY='your-api-key-here'

# For Windows (Command Prompt)
set OPENAI_API_KEY=your-api-key-here

# For Windows (PowerShell)
$env:OPENAI_API_KEY='your-api-key-here'
```

You can also add this to your shell's startup file (.bashrc, .zshrc, etc.) for persistence.

## File Processing Methods

### PDF Files
Two extraction methods are available:
1. **Text and Images** (`text_and_images`):
   - Extracts text and embedded images separately
   - Preserves original text content and formatting
   - Best for PDFs where text extraction is reliable

2. **Page as Image** (`page_as_image`):
   - Converts each page to a high-resolution image (300 DPI)
   - Captures exact visual appearance including layout and formatting
   - Better for PDFs with complex layouts or when text extraction is unreliable

### DOCX Files
Two extraction methods are available:
1. **Text and Images** (`text_and_images`):
   - Extracts text and embedded images separately
   - Preserves original text formatting
   - Best for documents where text content needs to be preserved exactly

2. **Page as Image** (`page_as_image`):
   - Converts each page to an image
   - Captures exact visual appearance including layout
   - Requires LibreOffice for PDF conversion

### PPTX Files
- Converts each slide to an image using LibreOffice
- Captures exact visual appearance of slides
- Generates descriptions for each slide

## Usage

### Command-line Arguments
- `--source` or `-s`: Source folder path (default: `./content/source`)
- `--output` or `-o`: Output folder path (default: `./content/extracted`)
- `--type` or `-t`: File type to process ("pdf", "docx", or "pptx")

### Examples

1. Process DOCX files with default paths:
   ```bash
   poetry run python main.py --type docx
   ```

2. Process PDF files with custom paths:
   ```bash
   poetry run python main.py --source /path/to/source --output /path/to/output --type pdf
   ```

### Output Format
All extraction methods generate:
1. A Markdown file containing:
   - Document title
   - Page/slide numbers
   - Extracted text (for text-based methods)
   - Image descriptions
2. Clean directory structure:
   ```
   content/
   ├── extracted/
   │   └── document_name/
   │       └── document_name.md
   ├── source/
   │   └── (your source files)
   └── log/
       └── file_extractor_YYYYMMDD_HHMMSS.log
   ```

### Logging
The application maintains detailed logs of all operations:
- Logs are stored in `content/log/` with timestamp-based filenames
- Each run creates a new log file: `file_extractor_YYYYMMDD_HHMMSS.log`
- Logs include:
  - Timestamp for each operation
  - Processing steps and their status
  - Error messages and warnings
  - Extraction method used
  - Input and output file paths

## Testing

### Running Tests
Tests are implemented using pytest and can be run with:
```bash
# Run all tests
poetry run pytest -v

# Run specific test suites
# Run file extraction tests
poetry run pytest tests/test_file_extraction.py -v

# Run image description tests
poetry run pytest tests/test_image_description.py -v
```

### Test Coverage
The test suite includes integration tests that verify:
1. File processing for all supported formats (PDF, DOCX, PPTX)
2. Output directory structure and file generation
3. Logging system functionality
4. Basic error handling
5. Image Description functionality with different models

### Test Plan Status

1. Basic Extraction Tests
   - [x] PDF Extraction
     - [x] Verify output directory structure
     - [x] Check markdown file generation
     - [x] Test logging integration
   
   - [x] DOCX Extraction
     - [x] Verify output directory structure
     - [x] Check markdown file generation
     - [x] Test logging integration
   
   - [x] PPTX Extraction
     - [x] Verify output directory structure
     - [x] Check markdown file generation
     - [x] Test logging integration

2. Image Description Tests
   - [x] Local Llama Model Integration
     - [x] Verify successful execution
     - [x] Check description generation
     - [x] Validate output format
   
   - [x] OpenAI GPT-3 Integration
     - [x] Verify successful execution
     - [x] Check description generation
     - [x] Validate output format
     - [x] Handle missing API key gracefully

3. Core Operations
   - [x] File type detection and handling
   - [x] Directory structure creation
   - [x] Output file generation
   - [x] Basic error handling
   - [x] CLI parameter handling
   - [x] Model selection and switching

4. Logging System
   - [x] Verify log file creation
   - [x] Check log content format
   - [x] Validate timestamp accuracy

### Future Test Improvements
1. Content Validation
   - [ ] Verify text extraction accuracy
   - [ ] Check image quality and preservation
   - [ ] Validate markdown content structure
   - [ ] Compare descriptions from different models
   - [ ] Test with various image types (PNG, JPEG, etc.)

2. Error Handling
   - [ ] Test invalid file formats
   - [ ] Handle missing dependencies
   - [ ] Test permission issues
   - [ ] Network error handling
   - [ ] Test Ollama server connection issues
   - [ ] Test invalid API keys

3. Performance Testing
   - [ ] Measure processing time
   - [ ] Memory usage monitoring
   - [ ] Large file handling
   - [ ] Compare model performance
   - [ ] Test with large images

4. Integration Testing
   - [ ] Multiple file processing
   - [ ] Concurrent operations
   - [ ] System resource management
   - [ ] Test batch processing

## License

This project is licensed under the [MIT License](LICENSE).

## Image Description

The application supports three main use cases for image description:

1. **Local Description with Llama** (Default)
   - Uses Ollama with `llama3.2-vision` model
   - Runs completely locally
   - No API key required
   - Best for: Development, testing, and offline use
   - Decent accuracy with good performance

2. **Cloud Description with GPT-4 Vision**
   - Uses OpenAI's `gpt-4-vision-preview` model
   - Requires OpenAI API key
   - Best for: Production use, highest accuracy
   - Most expensive option

3. **Cloud Description with GPT-3 Vision**
   - Uses OpenAI's `gpt-3-vision` model
   - Requires OpenAI API key
   - Best for: Production use with cost constraints
   - Good balance of accuracy and cost

### Using the Image Description CLI

Test the different use cases with our CLI tool:

```bash
# 1. Local Description with Llama (default)
poetry run python describe_image_cli.py -i path/to/image.png

# 2. Cloud Description with GPT-4 Vision
poetry run python describe_image_cli.py -i path/to/image.png -u gpt4 --api-key YOUR_API_KEY

# 3. Cloud Description with GPT-3 Vision
poetry run python describe_image_cli.py -i path/to/image.png -u gpt3 --api-key YOUR_API_KEY

# Additional Options:
# Save description to file
poetry run python describe_image_cli.py -i path/to/image.png -o description.txt

# Verbose mode (shows processing details)
poetry run python describe_image_cli.py -i path/to/image.png -v
```

### Comparing Models

Each model has its strengths:

1. **Llama (llama3.2-vision)**
   - ✅ Free to use
   - ✅ Runs locally
   - ✅ No data leaves your machine
   - ⚠️ Requires more system resources
   - ⚠️ Slightly lower accuracy

2. **GPT-4 Vision**
   - ✅ Highest accuracy
   - ✅ Best understanding of context
   - ✅ Most detailed descriptions
   - ⚠️ Most expensive
   - ⚠️ Requires internet connection

3. **GPT-3 Vision**
   - ✅ Good accuracy
   - ✅ Faster than GPT-4
   - ✅ More cost-effective
   - ⚠️ Less detailed than GPT-4
   - ⚠️ Requires internet connection
